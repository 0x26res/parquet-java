
// ALL TESTS GREEN

!!! Asi musim zapisovat protobuffer zpatky v MessageConverter.end()


soucasna chyba: mozna tam mam jeden repeated level navic:
message TestProtobuf.RepeatedInnerMessage {
  repeated group internal (LIST) {
    repeated group internal_tuple {
      optional int32 int;
    }
  }
}



protobuffery muzou byt rekurzivni. Pokud rekurzi detekuju, tak bych mel treba treti level delat lazy.
! jak zpracovavat repeated fieldy ? Je to vlastne Avro pole.
OPTIONAL: Udelat lepsi varovani pro required fieldy.



!!! ja bych mel identifikovat fieldy podle cisel, ne podle jmen. Cisla jsou k tomu urcena.
Podivat se na Thrift, tam to bude lepsi nez v Avru.
Nejspis se jedna o tridu ThriftSchemaConverter - metoda toThriftField
return new ThriftField(name, field.getId(), requirement, type);

TODO: spravit unit testy.

Otestovat psani msg
Testovat zpravy o vice fieldech.
zkontrolovat zapis poli - jestli se tam dobre volaji zacatky a konce


subProtobuffer je asi nutny vzdycky ulozit zpatky.

ThriftSchemaConvertVisitor - tam se konvertuj typy v thriftu.


Jak se pri cteni mapuji jmena fieldu:
1. Avro. Projde schema ulozene v souboru a namatchuje se podle jmena fieldu
2. Thrift zapisuje si extra informace. Ma v hlavicce zapsany svuj descriptor ( a tridu)
  matchovani probiha v konstruktoru StructConverter v ThriftRecordConverter
  !!! a je to take podle jmena !!! ;))))

Ja konvertuju v ProtoWriteSupport, Avro ma to same.
Ja pouzivam protobufferove indexy, to je spatne.
Avro dostane fieldy tak serazene ze muze pouzit jejich index v poli
V Thrift se o to staraa ParquetWriteProtocol
Thrift pouziva mapovani thrift id -> parquet typ -> parquet id. Tak to chci udelat ja.
Me nestaci udelat jen protokol na zpravy a mozna pole protoze pro me bude vyhodne delat datove konverze primitivnich typu.

Ja bych si mohl tak udelat slozeni trid. Bude se konstruovat pomoci ProtobufRecordSerializeru

Co se pri zapisu musi delat: Zpravy musi byt uzavrene v group
uzavirat fieldy s indexem
spravne uzavreni pole. S polem by mohl byt problem.
konverze fieldu

jak to udelat: initWrite
writery fieldu budou asi hloupe. Budou jen konvertovat.
Nebudu mit s polema problem ze tam musi byt pomocna trida ParentValue ?
Imho ne.
Jak mam pri zapisovani prochazet strom ? Zalezi na tom ?


mapovani je v  ParquetWriteProtocol::StructWriteProtocol

Odpoved je mozna v GroupType:

  public GroupType(Repetition repetition, String name, OriginalType originalType, List<Type> fields) {
    super(name, repetition, originalType);
    this.fields = fields;
    this.indexByName = new HashMap<String, Integer>();
    for (int i = 0; i < fields.size(); i++) {
      indexByName.put(fields.get(i).getName(), i);
    }

To by znamenalo ze ty intexy jsou rekurzivni, platne jen v ramci jedne zpravy


public RecordMaterializer<T> prepareForRead(Configuration configuration,
      Map<String, String> keyValueMetaData, MessageType fileSchema,
      parquet.hadoop.api.ReadSupport.ReadContext readContext) {
    ThriftMetaData thriftMetaData = ThriftMetaData.fromExtraMetaData(keyValueMetaData);
    try {


    }
ToDo: Najit propojeni na Grouptype v Avru


